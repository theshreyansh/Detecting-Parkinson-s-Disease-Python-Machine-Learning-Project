{"cells":[{"metadata":{},"cell_type":"markdown","source":"### Detecting Parkinson’s Disease – Python Machine Learning Project\n#### What is Parkinson’s Disease?\nParkinson’s disease is a progressive disorder of the central nervous system affecting movement and inducing tremors and stiffness. It has 5 stages to it and affects more than 1 million individuals every year in India. This is chronic and has no cure yet. It is a neurodegenerative disorder affecting dopamine-producing neurons in the brain.\n\n#### What is XGBoost?\nXGBoost is a new Machine Learning algorithm designed with speed and performance in mind. XGBoost stands for eXtreme Gradient Boosting and is based on decision trees. In this project, we will import the XGBClassifier from the xgboost library; this is an implementation of the scikit-learn API for XGBoost classification.\n\nIn this Python machine learning project, using the Python libraries scikit-learn, numpy, pandas, and xgboost, we will build a model using an XGBClassifier. We’ll load the data, get the features and labels, scale the features, then split the dataset, build an XGBClassifier, and then calculate the accuracy of our model\n\n#### Prerequisites\npip install numpy pandas sklearn xgboost\n\n#### Steps for Detecting Parkinson’s Disease with XGBoost"},{"metadata":{},"cell_type":"markdown","source":"#### 1. Make necessary imports:"},{"metadata":{"trusted":true},"cell_type":"code","source":"import numpy as np\nimport pandas as pd\nimport os, sys\nfrom sklearn.preprocessing import MinMaxScaler\nfrom xgboost import XGBClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score","execution_count":12,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 2. Now, let’s read the data into a DataFrame and get the first 5 records"},{"metadata":{"trusted":true},"cell_type":"code","source":"df=pd.read_csv('../input/datasetparkinsons/parkinsons.data')\ndf.head()","execution_count":14,"outputs":[{"output_type":"execute_result","execution_count":14,"data":{"text/plain":"             name  MDVP:Fo(Hz)  MDVP:Fhi(Hz)  MDVP:Flo(Hz)  MDVP:Jitter(%)  \\\n0  phon_R01_S01_1      119.992       157.302        74.997         0.00784   \n1  phon_R01_S01_2      122.400       148.650       113.819         0.00968   \n2  phon_R01_S01_3      116.682       131.111       111.555         0.01050   \n3  phon_R01_S01_4      116.676       137.871       111.366         0.00997   \n4  phon_R01_S01_5      116.014       141.781       110.655         0.01284   \n\n   MDVP:Jitter(Abs)  MDVP:RAP  MDVP:PPQ  Jitter:DDP  MDVP:Shimmer  ...  \\\n0           0.00007   0.00370   0.00554     0.01109       0.04374  ...   \n1           0.00008   0.00465   0.00696     0.01394       0.06134  ...   \n2           0.00009   0.00544   0.00781     0.01633       0.05233  ...   \n3           0.00009   0.00502   0.00698     0.01505       0.05492  ...   \n4           0.00011   0.00655   0.00908     0.01966       0.06425  ...   \n\n   Shimmer:DDA      NHR     HNR  status      RPDE       DFA   spread1  \\\n0      0.06545  0.02211  21.033       1  0.414783  0.815285 -4.813031   \n1      0.09403  0.01929  19.085       1  0.458359  0.819521 -4.075192   \n2      0.08270  0.01309  20.651       1  0.429895  0.825288 -4.443179   \n3      0.08771  0.01353  20.644       1  0.434969  0.819235 -4.117501   \n4      0.10470  0.01767  19.649       1  0.417356  0.823484 -3.747787   \n\n    spread2        D2       PPE  \n0  0.266482  2.301442  0.284654  \n1  0.335590  2.486855  0.368674  \n2  0.311173  2.342259  0.332634  \n3  0.334147  2.405554  0.368975  \n4  0.234513  2.332180  0.410335  \n\n[5 rows x 24 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>name</th>\n      <th>MDVP:Fo(Hz)</th>\n      <th>MDVP:Fhi(Hz)</th>\n      <th>MDVP:Flo(Hz)</th>\n      <th>MDVP:Jitter(%)</th>\n      <th>MDVP:Jitter(Abs)</th>\n      <th>MDVP:RAP</th>\n      <th>MDVP:PPQ</th>\n      <th>Jitter:DDP</th>\n      <th>MDVP:Shimmer</th>\n      <th>...</th>\n      <th>Shimmer:DDA</th>\n      <th>NHR</th>\n      <th>HNR</th>\n      <th>status</th>\n      <th>RPDE</th>\n      <th>DFA</th>\n      <th>spread1</th>\n      <th>spread2</th>\n      <th>D2</th>\n      <th>PPE</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>phon_R01_S01_1</td>\n      <td>119.992</td>\n      <td>157.302</td>\n      <td>74.997</td>\n      <td>0.00784</td>\n      <td>0.00007</td>\n      <td>0.00370</td>\n      <td>0.00554</td>\n      <td>0.01109</td>\n      <td>0.04374</td>\n      <td>...</td>\n      <td>0.06545</td>\n      <td>0.02211</td>\n      <td>21.033</td>\n      <td>1</td>\n      <td>0.414783</td>\n      <td>0.815285</td>\n      <td>-4.813031</td>\n      <td>0.266482</td>\n      <td>2.301442</td>\n      <td>0.284654</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>phon_R01_S01_2</td>\n      <td>122.400</td>\n      <td>148.650</td>\n      <td>113.819</td>\n      <td>0.00968</td>\n      <td>0.00008</td>\n      <td>0.00465</td>\n      <td>0.00696</td>\n      <td>0.01394</td>\n      <td>0.06134</td>\n      <td>...</td>\n      <td>0.09403</td>\n      <td>0.01929</td>\n      <td>19.085</td>\n      <td>1</td>\n      <td>0.458359</td>\n      <td>0.819521</td>\n      <td>-4.075192</td>\n      <td>0.335590</td>\n      <td>2.486855</td>\n      <td>0.368674</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>phon_R01_S01_3</td>\n      <td>116.682</td>\n      <td>131.111</td>\n      <td>111.555</td>\n      <td>0.01050</td>\n      <td>0.00009</td>\n      <td>0.00544</td>\n      <td>0.00781</td>\n      <td>0.01633</td>\n      <td>0.05233</td>\n      <td>...</td>\n      <td>0.08270</td>\n      <td>0.01309</td>\n      <td>20.651</td>\n      <td>1</td>\n      <td>0.429895</td>\n      <td>0.825288</td>\n      <td>-4.443179</td>\n      <td>0.311173</td>\n      <td>2.342259</td>\n      <td>0.332634</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>phon_R01_S01_4</td>\n      <td>116.676</td>\n      <td>137.871</td>\n      <td>111.366</td>\n      <td>0.00997</td>\n      <td>0.00009</td>\n      <td>0.00502</td>\n      <td>0.00698</td>\n      <td>0.01505</td>\n      <td>0.05492</td>\n      <td>...</td>\n      <td>0.08771</td>\n      <td>0.01353</td>\n      <td>20.644</td>\n      <td>1</td>\n      <td>0.434969</td>\n      <td>0.819235</td>\n      <td>-4.117501</td>\n      <td>0.334147</td>\n      <td>2.405554</td>\n      <td>0.368975</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>phon_R01_S01_5</td>\n      <td>116.014</td>\n      <td>141.781</td>\n      <td>110.655</td>\n      <td>0.01284</td>\n      <td>0.00011</td>\n      <td>0.00655</td>\n      <td>0.00908</td>\n      <td>0.01966</td>\n      <td>0.06425</td>\n      <td>...</td>\n      <td>0.10470</td>\n      <td>0.01767</td>\n      <td>19.649</td>\n      <td>1</td>\n      <td>0.417356</td>\n      <td>0.823484</td>\n      <td>-3.747787</td>\n      <td>0.234513</td>\n      <td>2.332180</td>\n      <td>0.410335</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 24 columns</p>\n</div>"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### 3. Get the features and labels from the DataFrame (dataset). The features are all the columns except ‘status’, and the labels are those in the ‘status’ column."},{"metadata":{"trusted":true},"cell_type":"code","source":"features=df.loc[:,df.columns!='status'].values[:,1:]\nlabels=df.loc[:,'status'].values","execution_count":15,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 4. The ‘status’ column has values 0 and 1 as labels; let’s get the counts of these labels for both- 0 and 1. We have 147 ones and 48 zeros in the status column in our dataset."},{"metadata":{"trusted":true},"cell_type":"code","source":"print(labels[labels==1].shape[0], labels[labels==0].shape[0])","execution_count":16,"outputs":[{"output_type":"stream","text":"147 48\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"#### 5. Initialize a MinMaxScaler and scale the features to between -1 and 1 to normalize them. The MinMaxScaler transforms features by scaling them to a given range. The fit_transform() method fits to the data and then transforms it. We don’t need to scale the labels."},{"metadata":{"trusted":true},"cell_type":"code","source":"scaler=MinMaxScaler((-1,1))\nx=scaler.fit_transform(features)\ny=labels","execution_count":17,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 6. Now, split the dataset into training and testing sets keeping 20% of the data for testing.\n"},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train,x_test,y_train,y_test=train_test_split(x, y, test_size=0.2, random_state=7)","execution_count":18,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"#### 7. Initialize an XGBClassifier and train the model. This classifies using eXtreme Gradient Boosting- using gradient boosting algorithms for modern data science problems. It falls under the category of Ensemble Learning in ML, where we train and predict using many models to produce one superior output."},{"metadata":{"trusted":true},"cell_type":"code","source":"model=XGBClassifier()\nmodel.fit(x_train,y_train)","execution_count":19,"outputs":[{"output_type":"execute_result","execution_count":19,"data":{"text/plain":"XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=1, gamma=0, gpu_id=-1,\n              importance_type='gain', interaction_constraints='',\n              learning_rate=0.300000012, max_delta_step=0, max_depth=6,\n              min_child_weight=1, missing=nan, monotone_constraints='()',\n              n_estimators=100, n_jobs=0, num_parallel_tree=1, random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n              tree_method='exact', validate_parameters=1, verbosity=None)"},"metadata":{}}]},{"metadata":{},"cell_type":"markdown","source":"#### 8. Finally, generate y_pred (predicted values for x_test) and calculate the accuracy for the model. Print it out."},{"metadata":{"trusted":true},"cell_type":"code","source":"y_pred=model.predict(x_test)\nprint(accuracy_score(y_test, y_pred)*100)","execution_count":20,"outputs":[{"output_type":"stream","text":"94.87179487179486\n","name":"stdout"}]},{"metadata":{},"cell_type":"markdown","source":"## Summary\nIn this Python machine learning project, we learned to detect the presence of Parkinson’s Disease in individuals using various factors. We used an XGBClassifier for this and made use of the sklearn library to prepare the dataset. This gives us an accuracy of 94.87%, which is great considering the number of lines of code in this python project."}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}